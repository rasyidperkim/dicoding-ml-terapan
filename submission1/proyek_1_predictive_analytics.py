# -*- coding: utf-8 -*-
"""Proyek_1_Predictive_Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YL0SicDSkAz9-f9N94cT7ryYL67uigWe

## **Predictive Analytics Case**

**M. Rasyid Ridha**

Data yang digunakan pada proyek ini bersumber dari Kaggle pada tautan berikut ini [Daftar Harga Rumah Jabodetabek](https://www.kaggle.com/datasets/nafisbarizki/daftar-harga-rumah-jabodetabek). Menurut sumber, data daftar harga rumah ini diakses dari berdasarkan salah satu web listing di Indonesia yaitu https://rumah123.com pada akhir tahun 2022. **Dataset yang dipakai berupa data kuantitatif yang berisi 3553 baris (termasuk header)**

### Variabel-variabel pada Daftar Harga Rumah Jabodetabek dalam dataset adalah sebagai berikut:

* url : data link website penjualan rumah
* price_in_rp : harga rumah dalam rupiah
* title : judul promosi penjualan rumah
* address : alamat rumah yang dijual
* district : lokasi kawasan rumah
* city : keterangan kota lokasi rumah
* lat : data geografis rumah berdasarkan garis lintang
* long : data geografis rumah berdasarkan garis bujur
* facilities : fasilitas yang didapatkan di lingkungan perumahan
* property_tipe : jenis properti
* ads_id : nomor id iklan pada website
* bedrooms : jumlah kamar tidur tersedia
* bathrooms : jumlah kamar mandi tersedia
* land_size_m2 : luas tanah hunian
* building_size_m2 : luas bangunan hunian
* carports : ketersedian carport pada rumah
* certificate : legalitas properti
* electricity : kapasitas daya listrik dengan satuan mah
* maid_bedrooms : jumlah kamar pembantu tersedia
* maid_bathrooms : jumlah kamar mandi pembantu tersedia
* floors : jumlah lantai terbangun
* building_age : umur bangunan
* year_built : tahun pembangunan
* property_condition : keterangan kondisi rumah
* building_orientation : orientasi mata angin bangunan
* garages : jumlah garasi
* furnishing : tingkat kelengkapan atau ketersediaan perabotan dan peralatan

Kita panggil library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import xgboost as xgb
from scipy.stats import f_oneway
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

"""Selanjutnya kita memanggil dataset dengan format csv"""

url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQ2Iblmh59rC190eOX1eep__U9I54JKtbnJufI0t5qJk_wQpxiDh6bc8Nb05KZBszHyjWJdYqCiAeRU/pub?output=csv'
df = pd.read_csv(url)

"""Data Overview

Berikut adalah sampel 5 data teratas dari dataset yang digunakan.
"""

#Menampilkan 5 sampel data teratas
df.head()

"""Dependent variabel atau target feature kita adalah kolom price_in_rp. Kita ingin melihat jumlah baris dan kolom yang ada dalam dataset ini"""

##Menampilkan jumlah baris (termasuk header) dan kolom (features)
df.shape

"""Dataset yang digunakan terdiri dari 3.553 baris dan 27 kolom. Selanjutnya kita ingin melihat informasi jumlah data, tipe data, dan memori yang digunakan"""

#Melihat informasi data mulai dari jumlah data, tipe data, memory yang digunakan dll.
df.info()

"""Dari informasi di atas kita ketahui :
1. Ada 16 data teks objek dan 11 data numerik. Data price dideteksi sebagai data object padahal ini merupakan data target yang mesti diprediksi sehingga kita perlu ubah menjadi data numerik.
2. Ada data yang kosong yang perlu kita identifikasi jumlahnya

Pertama mari kita konversi data target menjadi numerik.
"""

# Membuat fungsi konversi data objek price_in_rp menjadi data numerik (integer)
def process_price(price):
    price = price.replace('.', '')
    return int(price)

# terapkan fungsi pada kolom 'price_in_rp'
df['price_in_rp'] = df['price_in_rp'].apply(process_price)

# Display the first 5 rows
df['price_in_rp']

"""Selanjutnya kita identifikasi jumlah data kosong (missing value)"""

#Mengetahui jumlah missing value dengan satuan persentase dari data total
missing_values = df.isnull().sum()[df.isnull().sum() > 0]
missing_values = pd.DataFrame(missing_values.reset_index())
missing_values.rename(columns={'index':'Features', 0:'Count'}, inplace=True)
missing_values['Percentage'] = missing_values['Count'] / len(df) * 100
missing_values.sort_values(by='Percentage', ascending=False, inplace=True)

#Membuat diagram bar jumlah missing value
sns.barplot(x='Percentage', y='Features', data=missing_values)

# Tampilkan informasi pola missing value
print("Informasi Pola Missing Value:")
print(missing_values)

"""Ada 3 feature yang memiliki missing value lebih dari 11 % data sehingga kita hapus saja karena terlalu banyak missing value yang akan berpengaruh ke model jika diimputisasi. Selain itu pada price_in_rp sebagai target feature juga ada missing value yang akan kita hapus pada baris data yang kosong."""

#Hapus kolom dengan persentase tinggi pada missing values
df_clean = df.drop(['building_orientation', 'building_age', 'year_built'], axis=1)

"""Adapun berikut adalah ringkasan statistik dari data-data numerikal."""

#Melihat statistical description dari data mulai dari mean, kuartil, standard deviation dll.
df_clean.describe()

"""Dari data ini dapat kita ambil informasi :
1. Berdasarkan count, ada missing value pada price_in_rp, bedrooms, bathrooms, land_size_m2, building_size_m2, dan floors.
2. Untuk imputisasi pada missing value sebaiknya tidak menggunakan mean pada bedrooms, bathrooms, dan floor karena isi datanya harus berupa integer tanpa koma.
3. Dari nilai min, ada data dari land_size_m2 building_size_m2 yang secara ukuran janggal
4. land_size_m2 harus lebih besar dari building_size_m2, sehingga jika ada yang tidak demikian perlu kita drop.
5. Nilai 75 % dan nilai max sangat jauh, sehingga kita harus melakukan penghapusan outlier agar model tidak terganggu

### EDA (Exploratory Data Analysis)

Disini kita perlu melakukan pembersihan dan perbaikan data sehingga analisa menjadi lebih tepat. Pertama kita perlu memeriksa data duplikat karena ada kemungkinan pengiklan mempublikasi iklan mereka secara berulang yang mana direkam dengan url yang berbeda padahal isinya sama.
"""

#Mengetahui jumlah data duplikat
duplicates_nos = len(df_clean[df_clean.drop(['facilities', 'url'], axis=1).duplicated()])
print(f'Jumlah Data Duplikat: {duplicates_nos}')

"""Jumlah data duplikat ada sebanyak 92 buah dan selanjutnya kita hapus"""

#Menghapus data duplikat
df_clean.drop(
    df_clean[df_clean.drop(['facilities', 'url'], axis=1).duplicated()].index,
    inplace=True
    )
duplicates_nos = len(df_clean[df_clean.drop('facilities', axis=1).iloc[:, 1:-1].duplicated()])
print(f'Jumlah Data Duplikat: {duplicates_nos}')

"""Sekarang kita lihat informasi, tipe data pada masing-masing feature untuk dinilai kebenarannya."""

df_clean.info()

"""Mari kita eksplorasi data bertipe kategori terlebih dahulu. Beberapa fitur memiliki tipe data yang kurang sesuai. Beberapa fitur seharusnya termasuk dalam tipe data kategori misalnya certificate, property_condition, dan furnishing. Selain itu biasanya juga data tersebut juga berupa urutan bertingkat dari tipe atau statusnya"""

#Mengkonversi tipe data sebagian object menjadi tipe data category
category_column = ['certificate', 'property_condition', 'furnishing']
df_clean[category_column] = df_clean[category_column].astype('category')

#Melihat perubahan tipe data
df_clean[category_column].info()

"""Kita ingin melihat jumlah label apa saja yang ada pada data bertipe objek dan category sehingga kita bisa memperbaiki kesalahan pelabelan atau membersihkan label data yang terlalu banyak/bervariasi"""

categorical_columns = df_clean.select_dtypes(include=['object','category']).columns
for column in categorical_columns:
    print('Jumlah unique label pada data', column, ':', df_clean[column].nunique())

"""Dari hasil analisis di atas kita temukan informasi sebagai berikut :
1. Kita menemukan kategori yang memiliki jumlah yang terlalu banyak yaitu url, title, address, district, lat, long, facilities, ads_id
2. Kita menemukan kategori yang hanya memiliki satu data yaitu property_type.
3. Data electricity harusnya menjadi tipe data numerik.

Maka kita akan menghapus kategori tersebut dari dataset dan memilih kategori yang cocok.
"""

df_clean = df_clean.drop(['url', 'title', 'address', 'district', 'lat', 'long', 'facilities', 'ads_id', 'property_type'], axis=1)

"""Selain itu kita juga akan memeriksa kejanggalan data dimana ada data yang luas bangunan lebih besar daripada luas lahan. Mari kita bersihkan data dengan kriteria demikian terlebih dahulu."""

# identifikasi data yang luas bangunan lebih besar daripada luas lahan
df_specific = df_clean[(df_clean['building_size_m2'] > df_clean['land_size_m2'])].sort_values(by=['land_size_m2'], ascending=True)

# tampilkan jumlah row pada dataframe
df_specific

"""Kejanggalan data ini karena kemungkinan tertukar atau salah penginputan. Oleh karena itu selanjutnya kita hapus saja."""

# Ambil baris spesifik df_specific
indices_to_drop = df_specific.index

# Hapus data di dataframe berdasarkan df_specific
df_clean.drop(indices_to_drop, inplace=True)

"""Sebelum itu kita ingin melihat data luas bangunan dari urutan paling minimal untuk mendeteksi kejanggalan data."""

df_min_building = df_clean.sort_values(by=['building_size_m2'], ascending=True)

df_min_building.head(5)

"""Dari list tersebut bangunan berukuran 1 m2 dengan harga Rp. 170.000.000.000 dan bangunan dengan ukuran 18 m2 dengan harga Rp. 35.900.000.000 akan kita hapus karena dianggap janggal"""

# Hapus data bangunan dengan ukuran kurang dari 18 m2
df_clean = df_clean.drop(df_clean[df_clean['building_size_m2'] <= 18].index)

"""Setelah itu mari kita lihat isi variabel kategorikal"""

for column in category_column:
    categories = list(df_clean[column].dtypes.categories)
    print(column, '. Categories: ', categories, '\n')

"""Dari sini kita ketahui ada 2 fitur memiliki catatan bercampur dari kategori (misalnya, property_condition memiliki label dari furnishing, begitu juga dengan furnishing) sehingga bisa menyebabkan inkonsistensi untuk mengurutkan kategori ini. Mari periksa pengamatan-pengamatan tersebut."""

df_clean.loc[df_clean.property_condition.isin(['unfurnished', 'semi furnished']), 'property_condition'].value_counts()

"""Ada 9 label yang kurang tepat. Selanjutnya kita lihat pada fitur Furnishing."""

df_clean.loc[df_clean.furnishing == 'baru', 'furnishing'].value_counts()

"""Jumlahnya juga sama ada 9 label yang kurang tepat. Terindikasi kuat ada hubungan antar 9 label ini. Kita pastikan dulu hubungan tersebut."""

# Melihat hubungan label baru pada furnishing dengan property_condition
df_clean.loc[df_clean.furnishing == 'baru', ['furnishing', 'property_condition']]

"""Kedua kondisi pasangan dan jumlah pengamatan cocok dan saling tertukar kategorinya. Isian data tertukar antara kolom furnishing dan property_condition"""

# Mengubah data berlabel baru di furnishing
replace_furnish = df_clean.loc[df_clean.furnishing == 'baru', 'property_condition']
replace_furnish = pd.Categorical(replace_furnish, categories=['baru', 'furnished', 'semi furnished', 'unfurnished'])

df_clean.loc[ df_clean.furnishing == 'baru', 'furnishing'] = replace_furnish

#Tampilkan jumlah masing-masing label pada furnishing
df_clean.furnishing.value_counts()

"""Label 'baru' pada Furnishing sudah kita hilangkan. Kemudian kita hilangkan label 'semi furnished' dan 'unfurnished' pada property_condition"""

# Mengubah data berlabel semi furnished dan unfurnished di property_condition dan dijadikan label 'baru'
df_clean[df_clean.property_condition.isin(['semi furnished', 'unfurnished'])] = \
    df_clean[df_clean.property_condition.isin(['semi furnished', 'unfurnished'])].assign(
        property_condition='baru'
    )

#Tampilkan jumlah masing-masing label pada property_condition
df_clean.property_condition.value_counts()

"""Selanjutnya, kita perlu mengatur ulang kategori pada tiap-tiap fitur."""

df_clean = df_clean.assign(
    furnishing=pd.Categorical(
        df_clean.furnishing,
        categories=list(df_clean.furnishing.dropna().unique())
        )
    )
df_clean = df_clean.assign(
    property_condition=pd.Categorical(
        df_clean.property_condition,
        categories=list(df_clean.property_condition.dropna().unique())
        )
    )
for column in ['property_condition', 'furnishing']:
    categories = list(df_clean[column].dtypes.categories)
    print(column, '. Categories: ', categories, '\n')

"""Sekarang label sudah benar. Kemudian dari informasi sebelumnya, Electricity seharusnya bukan object tapi data numerik. Sekarang kita konversi Electricity menjadi data numerik dengan susunan berdasarkan daya energi atau charge. Dan yang harus dilakukan terlebih dahulu menghapus data teks dari electricity"""

# Fungsi untuk menghapus teks dari data 'electricity' data dan mengubah formatnya menjadi numerik integer
def sort_elect(string_value):
    if pd.isnull(string_value):
        return None
    num_value = re.findall(r'\d+', string_value)
    if len(num_value) == 0:
        return 0
    else:
        return int(num_value[0])

# Apply the function to the 'electricity' column
df_clean['electricity'] = df_clean['electricity'].apply(sort_elect)

"""Setelah berbagai proses tadi, mari kita lihat jumlah dan tipe data sekarang"""

df_clean.info()

"""Tipe data pada bedrooms, bathrooms, floors, carports, maid_bedrooms, maid_bathrooms, dan garages seharusnya berpola integer karena tidak mungkin dengan koma. Konversi tidak bisa dilakukan karena masih banyak missing value. Kita lanjutkan penanganan missing value dan outlier.

#### Missing Value and Outlier Solving

Penanganan missing value pada dataset ini kita gunakan beberapa cara.
1. Untuk data target feature yaitu **price_in_rp** yang kosong akan kita drop/hapus
2. Untuk data kategorikal seperti **furnishing**, **property_condition**, **certificate** dengan mengimputasi data missing value dengan menggunakan modus dari masing-masing variabel.
3. Untuk data numerik berpola integer (tanpa koma) seperti **bedrooms** ,**bathrooms** , **floors**, **electricity** dengan menggunakan median dari masing-masing variabel
4. Untuk data numerik seperti **land_size_m2** dan **building_size_m2** yang kosong akan kita drop/hapus

Mari kita lakukan.
"""

# Menghapus data missing value pada variabel price_in_rp, land_size_m2, dan building_size_m2
df_clean.dropna(subset=['price_in_rp','land_size_m2', 'building_size_m2'], inplace=True)

# Mengimputasi data missing value pada variabel kategorikal dengan modus
df_clean['furnishing'].fillna(df_clean['furnishing'].mode()[0], inplace=True)
df_clean['property_condition'].fillna(df_clean['property_condition'].mode()[0], inplace=True)
df_clean['certificate'].fillna(df_clean['certificate'].mode()[0], inplace=True)

# Mengimputasi data missing value pada variabel bedrooms, bathrooms, dan floors dengan median
df_clean['bedrooms'].fillna(df_clean['bedrooms'].median(), inplace=True)
df_clean['bathrooms'].fillna(df_clean['bathrooms'].median(), inplace=True)
df_clean['floors'].fillna(df_clean['floors'].median(), inplace=True)
df_clean['electricity'].replace(0, df_clean['electricity'].median(), inplace=True)

# Tampilkan informasi missing_values
missing_values = df_clean.isnull().sum()[df_clean.isnull().sum() > 0]
missing_values = pd.DataFrame(missing_values.reset_index())
missing_values.rename(columns={'index':'Features', 0:'Count'}, inplace=True)
print("Informasi Missing Value:")
print(missing_values)

"""Dari output kode terakhir, sudah tidak ada missing value lagi. Selanjutnya kita ingin memberikan penanganan data outlier (pecilan) pada data numerik"""

# Memilih feature numerik
numeric_columns = df_clean.select_dtypes(include=['int64', 'float64']).columns

# Memperkirakan jumlah baris yang diperlukan untuk plots
n = len(numeric_columns)
n_rows = n // 2
if n % 2:
    n_rows += 1

fig, axs = plt.subplots(n_rows, 2, figsize=(10, n_rows*5))

# perulangan pembuatan plot setiap feature
for ax, col in zip(axs.flatten(), numeric_columns):
    sns.boxplot(x=df_clean[col], ax=ax)
    ax.set_title(f'Boxplot of {col}', fontsize=14)

# If there's an odd number of numeric columns, delete the last Axes object
if n % 2:
    fig.delaxes(axs.flatten()[-1])

plt.tight_layout()
plt.show()

"""Dari boxplot ini ketahui semua numerical features memiliki outlier. Berikutnya, kita akan melakukan penanganan outlier ini dengan metode IQR"""

# Penanganan outlier pada semua data numerik dengan metode IQR
for col in numeric_columns:
    Q1 = df_clean[col].quantile(0.25)
    Q3 = df_clean[col].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df_clean[col] = df_clean[col].clip(lower_bound, upper_bound)

# Mengubah sebagian fitur menjadi integer untuk menjadi bilangan bulat tanpa koma
integer_columns = ['bedrooms', 'bathrooms', 'floors', 'carports', 'maid_bedrooms', 'maid_bathrooms', 'garages']
df_clean[integer_columns] = df_clean[integer_columns].astype(int)

"""Mari kita lihat boxplot dari data yang sudah ditangani outlier tersebut"""

# Tampilkan boxplot sesudah penanganan outlier
fig, axs = plt.subplots(n_rows, 2, figsize=(10, n_rows*5))

for ax, col in zip(axs.flatten(), numeric_columns):
    sns.boxplot(x=df_clean[col], ax=ax)
    ax.set_title(f'Boxplot of {col}', fontsize=14)

if n % 2:
    fig.delaxes(axs.flatten()[-1])

plt.tight_layout()
plt.show()

"""Setelah itu kita ingin melihat statistik data setelah dibersihkan dari outlier"""

df_clean.describe(include='all')

"""Kita bisa melihat sekarang data numerik lebih bersih dan memiliki rentang yang normal. Selanjutnya kita akan menganalisis variabel kategorikal."""

categorical_columns = df_clean.select_dtypes(include=['object','category']).columns

"""#### **City**

Kita lihat jumlah sampel dan persentase masing-masing label
"""

feature = categorical_columns[0]
count = df_clean[feature].value_counts()
percent = 100*df_clean[feature].value_counts(normalize=True)
df_clean_category = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_clean_category)
count.plot(kind='bar', title=feature);

"""Data kolom **City** terbanyak adalah kota Bogor, yaitu sekitar 34,3 % rumah. Adapun yang paling sedikit, rumah yang berlokasi di Jakata Pusat dengan kontribusi sekitar 0,4 % saja. Variabel **City** ini merupakan variabel kategorikal nominal (tidak ada urutannya), sehingga encoding yang tepat untuk diterapkan adalah One-Hot Encoding. Untuk efektifitas encoding, kita akan menggabungkan label dengan awalan Jakarta menjadi Jakarta saja."""

# menggabungkan label dengan awalan Jakarta menjadi Jakarta saja.
df_clean['city'] = df_clean['city'].replace(['Jakarta Pusat', 'Jakarta Utara', 'Jakarta Selatan', 'Jakarta Timur', 'Jakarta Barat'], 'Jakarta')
count = df_clean['city'].value_counts()
print(count)

"""#### **Certificate**

Kita lihat jumlah sampel dan persentase masing-masing label
"""

feature = categorical_columns[1]
count = df_clean[feature].value_counts()
percent = 100*df_clean[feature].value_counts(normalize=True)
df_clean_category = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_clean_category)
count.plot(kind='bar', title=feature);

"""Data kolom Certificate terbanyak adalah SHM, yaitu sekitar 87,7 % rumah. Adapun yang paling sedikit, yaitu hp (Hak Pakai) dengan kontribusi sekitar 0,1 % saja karena hanya memiliki 1 jumlah data oleh karena itu akan kita hapus. Variabel Certificate ini merupakan variabel kategorikal ordinal sehingga encoding yang tepat untuk diterapkan adalah Ordinal Encoding."""

# ganti data 'hp - hak pakai' menjadi 'lainnya'
df_clean['certificate'].replace('hp - hak pakai', 'lainnya (ppjb,girik,adat,dll)', inplace=True)
count = df_clean['certificate'].value_counts()
print(count)

"""#### **Property Condition**

Kita lihat jumlah sampel dan persentase masing-masing label
"""

feature = categorical_columns[2]
count = df_clean[feature].value_counts()
percent = 100*df_clean[feature].value_counts(normalize=True)
df_clean_category = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_clean_category)
count.plot(kind='bar', title=feature);

"""Data kolom Property_condition terbanyak adalah 'bagus', yaitu sekitar 51,1 % dari rumah. Adapun yang paling sedikit, yaitu 'butuh renovasi' dengan kontribusi sekitar 3,4 % saja karena hanya memiliki 61 jumlah data. Variabel Property_condition ini merupakan variabel kategorikal ordinal sehingga encoding yang tepat untuk diterapkan adalah Ordinal Encoding.

#### **Furnishing**

Kita lihat jumlah sampel dan persentase masing-masing label
"""

feature = categorical_columns[3]
count = df_clean[feature].value_counts()
percent = 100*df_clean[feature].value_counts(normalize=True)
df_clean_category = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_clean_category)
count.plot(kind='bar', title=feature);

"""Data kolom Furnishing terbanyak adalah 'unfurnished', yaitu sekitar 77,3 % dari rumah, diikuti oleh semi furnished dengan 17,2 % dan furnished 5,5 %. Variabel Furnishing ini merupakan variabel kategorikal ordinal sehingga encoding yang tepat untuk diterapkan adalah Ordinal Encoding.

Selanjutnya, untuk fitur numerik, kita akan melihat histogram masing-masing fiturnya menggunakan code berikut.
"""

df_clean.hist(bins=50, figsize=(20,15))
plt.show()

"""Berikut interpretasi dari grafik yang bisa kita ambil :
* price_in_rp: Sebagian besar properti pada data ini memiliki harga di bawah 1.5 miliar Rupiah, dengan beberapa properti memiliki harga hingga 4.8 miliar Rupiah. Distribusi ini memiliki skew kanan, yang berarti ada beberapa properti dengan harga yang sangat tinggi yang mendorong rata-rata ke atas.

* bedrooms, bathrooms: Sebagian besar properti memiliki 2-3 kamar tidur dan 1-2 kamar mandi. Ada beberapa properti dengan lebih banyak kamar tidur dan kamar mandi

* land_size_m2, building_size_m2: Sebagian besar properti memiliki ukuran lahan dan bangunan di bawah 200 m2, dengan beberapa properti memiliki ukuran lahan dan bangunan yang jauh lebih besar. Distribusi ini juga skew ke kanan.

* carports: Semua properti memiliki 1 carport.

* electricity: Daya listrik sebagian besar antara 900 dan 2200, dengan beberapa properti memiliki daya listrik yang lebih rendah atau lebih tinggi.

* maid_bedrooms, maid_bathrooms: Sebagian besar properti tidak memiliki kamar tidur atau kamar mandi pembantu. Beberapa properti memiliki 1 atau 2 kamar tidur pembantu.

* floors: Sebagian besar properti memiliki 1 atau 2 lantai, dengan beberapa properti memiliki 3 lantai.

* garages: Sebagian besar properti tidak memiliki garasi, beberapa memiliki 1 atau 2 garasi.

Selanjutnya kita melakukan multivariate analysis.

#### Multivariate Analysis

Multivariate EDA menunjukkan hubungan antara dua atau lebih variabel pada data. Multivariate EDA yang menunjukkan hubungan antara dua variabel biasa disebut sebagai bivariate EDA. Kita akan melakukan analisis data pada categorical features terlebih dahulu dan dilanjutkan dengan numerical features

**Categorical Features**

Variabel target adalah price_in_rp yang bertipe data numerik dan kita akan melhat hubungan masing-masing dengan variabel kategori
"""

# Plot boxplots for categorical features
cat_cols = ['city', 'certificate', 'property_condition', 'furnishing']

fig, axs = plt.subplots(nrows=len(cat_cols), figsize=(10, 20))
for i, col in enumerate(cat_cols):
    sns.boxplot(x=col, y='price_in_rp', data=df_clean, ax=axs[i])
    axs[i].set_title(f'Boxplot of house price (Rp) by {col}', fontsize=15)
    axs[i].tick_params(axis='x')

plt.tight_layout()
plt.show()

"""Berikut adalah interpretasi dari boxplot untuk fitur kategorikal:

* city : Kota tempat properti berada memiliki pengaruh yang signifikan terhadap harga properti. Rata-rata properti di Jakarta cenderung memiliki harga yang lebih tinggi dibandingkan dengan kota-kota lain. Hal ini bisa jadi karena Jakarta sebagai ibukota dan memang pusat bisnis dan komersial, sehingga nilai properti di sana lebih tinggi. Namun, perlu diingat bahwa ada juga variasi harga yang besar seperti di kota Bekasi dan Depok, seperti ditunjukkan oleh outlier pada boxplot.

* certificate: Harga properti juga bervariasi berdasarkan jenis sertifikat. Properti dengan "SHM - Sertifikat Hak Milik" cenderung memiliki harga yang lebih tinggi dibandingkan dengan properti dengan sertifikat lainnya, hanya saja hubungan ini tidak terlalu signifikan.

* property_condition: Kondisi properti juga berpengaruh terhadap harga. Properti yang dalam kondisi "Bagus Sekali" cenderung memiliki harga yang lebih tinggi dibandingkan dengan properti dalam kondisi lain. Hanya saja hubungan ini tidak terlalu signifikan.

* furnishing: Perlengkapan properti atau furnishing juga berpengaruh terhadap harga. Properti yang dilengkapi perabotan cenderung memiliki harga yang lebih tinggi dibandingkan dengan properti yang tidak dilengkapi perabotan. Ini mungkin karena biaya tambahan untuk mebel dan dekorasi yang sudah ada di properti tersebut.Hanya saja hubungan ini tidak terlalu signifikan.

**Numerical Features**

Untuk mengamati hubungan antara fitur numerik, kita akan menggunakan fungsi pairplot(). Kita juga akan mengobservasi korelasi antara fitur numerik dengan fitur target menggunakan fungsi corr().
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df_clean, diag_kind = 'kde')

"""Dari scatterplot, kita dapat melihat hubungan antara setiap fitur numerik dengan target (price_in_rp). Meskipun tidak ada hubungan linear yang jelas antara fitur-fitur dan target, beberapa fitur seperti land_size_m2, building_size_m2, dan electricity tampak memiliki hubungan positif dengan target, yaitu ketika nilai fitur meningkat, harga juga cenderung meningkat.

Selanjutnya kita hapus dulu fitur 'carports' dan 'maid_bathrooms'yang hanya memiliki isi data yang sama (tidak memiliki varian).
"""

# Menghapus fitur yang tidak diperlukan
df_clean = df_clean.drop(['carports', 'maid_bathrooms'], axis=1)

"""Selanjutnya kita tampilkan matriks korelasi"""

plt.figure(figsize=(10, 8))
correlation_matrix = df_clean.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Dari matriks korelasi, kita dapat melihat korelasi antara setiap pasangan fitur. Nilai korelasi berkisar antara -1 hingga 1, di mana 1 berarti korelasi positif sempurna, -1 berarti korelasi negatif sempurna, dan 0 berarti tidak ada korelasi. Beberapa poin yang dapat kita ambil adalah:

* price_in_rp memiliki korelasi yang kuat dengan land_size_m2, building_size_m2, bedrooms, electricity, dan bathrooms. Bedrooms dan bathrooms juga memiliki korelasi yang kuat, yang masuk akal karena jumlah kamar tidur dan kamar mandi biasanya sebanding.
* land_size_m2 dan building_size_m2 memiliki korelasi yang sangat kuat, makin besar luas lahan biasanya makin besar juga luas bangunan
* electricity memiliki korelasi positif yang cenderung kuat dengan land_size_m2 dan building_size_m2, yang berarti properti dengan ukuran lahan dan bangunan yang lebih besar cenderung memiliki daya listrik yang lebih besar.

Dengan mempertimbangkan semua analisis ini, berikut adalah beberapa insight awal untuk fitur yang harus dipilih untuk model prediksi:

1. Semua Fitur numerik kecuali carport, garages, maid_bathrooms, dan floors harus dipertimbangkan karena mereka memiliki korelasi positif yang kuat hingga moderat dengan harga dan dapat memberikan informasi yang berharga untuk prediksi.
2. Fitur kategorikal 'City' harus dipertimbangkan karena mereka menunjukkan korelasi positif dan variasi yang signifikan dalam harga berdasarkan kategori mereka.

Selanjutnya pada tahap Data Preparation kita akan memilih fitur yang dianggap paling informatif dan berpengaruh dalam prediksi penentuan harga.

### Data Preparation

Pada bagian ini kita akan melakukan tahap persiapan data, yaitu:
* Encoding
* Fetaure Selection
* Train-test split
* standardization

#### Encoding

Untuk feature berupa kategorikal nominal (tanpa urutan) kita menggunakan Hot Encoding
"""

# Melakukan one-hot encoding pada fitur 'city'
one_hot_encoded = pd.get_dummies(df_clean['city'], prefix='city')

# Menggabungkan hasil one-hot encoding dengan dataframe asli
df_city = pd.concat([df_clean, one_hot_encoded], axis=1)
df_city = df_city.drop(['city'], axis=1)

# Menampilkan dataframe yang telah diencode
df_city.head(5)

"""Untuk feature berupa kategorikal ordinal kita menggunakan Ordinal Encoding"""

# menyusun data kategori
certificate_order = [
    'lainnya (ppjb,girik,adat,dll)', 'hgb - hak guna bangunan',
    'shm - sertifikat hak milik',
    ]
property_condition_order = [
     'butuh renovasi','sudah renovasi','baru','bagus','bagus sekali'
    ]

furnishing_order = [
      'unfurnished','semi furnished','furnished'
    ]

# Daftar fitur yang akan diencode
fitur_list = ['certificate', 'property_condition', 'furnishing']

# Membentuk dataframe kosong untuk menyimpan hasil encoding
df_encoded = pd.DataFrame()

# Melakukan ordinal encoding dengan perulangan
for fitur, order_list in zip(fitur_list, [certificate_order, property_condition_order, furnishing_order]):
    # Mengurutkan kategori fitur berdasarkan urutan tertentu
    mapping = {category: index for index, category in enumerate(order_list)}

    # Melakukan ordinal encoding pada fitur
    encoded_column = f'{fitur}_encoded'
    df_encoded[encoded_column] = df_clean[fitur].map(mapping)

# Menggabungkan df_encoded dengan df_city
df_encoded = pd.concat([df_city, df_encoded], axis=1)

#Menghapus fitur kategori pada df_encoded
df_encoded = df_encoded.drop(fitur_list, axis=1)

# Memastikan df_encoded telah tergabung secara benar
df_encoded.info()

"""#### Feature Selection

Langkah selanjutnya adalah melakukan seleksi fitur. Kita akan menggunakan metode f_classif dan chi2 untuk mengetahui fitur-fitur yang paling banyak berpengaruh terhadap target.
"""

from sklearn.feature_selection import SelectKBest, f_classif, chi2

# Memisahkan fitur dan target
X = df_encoded.drop('price_in_rp', axis=1)
y = df_encoded['price_in_rp']

# Melakukan seleksi fitur terbaik untuk fitur numerik dengan f_classif
selector_f_classif = SelectKBest(score_func=f_classif, k='all')
X_new_f_classif = selector_f_classif.fit_transform(X, y)

# Melakukan seleksi fitur terbaik untuk fitur numerik dengan chi2
selector_chi2 = SelectKBest(score_func=chi2, k='all')
X_new_chi2 = selector_chi2.fit_transform(X, y)

"""Selanjutnya kita tampilkan urutan skor dari yang tertinggi ke paling terendah"""

# Menampilkan skor dari seleksi fitur
for score_f, score_chi2, col in sorted(zip(selector_f_classif.scores_, selector_chi2.scores_, X.columns), key=lambda x: x[0], reverse=True):
    print(f'{col}: {score_f:.2f}, {score_chi2:.2f}')

"""Dari hasil analisa diketahui bahwa build_size_m2 dan land_size_m2 atau ukuran bangunan dan lahan memiliki pengaruh yang sangat signifikan terhadap harga rumah. Hanya saja metode ini tidak mempertimbangkan interaksi antara fitur. Oleh karena itu dalam model kita akan memasukkan 5 feature teratas ditambah 5 feature dari kota/city.

1. building_size_m2
2. land_size_m2
3. electricity
4. bathrooms
5. bedrooms
6. city_Depok
7. city_Bekasi
8. city_Tangerang
9. city_Jakarta
10. city_Bogor

#### Train-Test-Split

Dalam model ini kita menggunakan proporsi pemisahan 80:20 atau sekitar 300-an data uji sampel.
"""

# Select the features
selected_features = ['building_size_m2','land_size_m2','bathrooms','electricity','bedrooms', \
                     'city_Depok','city_Bekasi','city_Tangerang','city_Jakarta','city_Bogor']
X = X[selected_features]

# Perform train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Kita tampilkan jumlah masing-masing sampel"""

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""#### Standardization"""

from sklearn.preprocessing import StandardScaler

# Fitur-fitur yang akan distandarisasi
numeric_features = ['land_size_m2', 'building_size_m2', 'bedrooms', 'bathrooms', 'electricity']

# Mengambil subset fitur yang akan distandarisasi
X_train_selected = X_train[numeric_features]
X_test_selected = X_test[numeric_features]

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_selected)
X_test_scaled = scaler.transform(X_test_selected)

"""Setelah distandarisasi, kita gabung array-nya dengan fitur hasil encoding pilihan yang tidak ikut distandarisasi."""

# Fitur-fitur encoding tanpa standarisasi
encoding_features = ['city_Depok', 'city_Bekasi', 'city_Tangerang', 'city_Jakarta', 'city_Bogor']

# Mengambil subset fitur lain yang akan digabungkan
X_train_encode = X_train[encoding_features]
X_test_encode = X_test[encoding_features]

# Menggabungkan fitur-fitur yang sudah distandarisasi dengan fitur-fitur lain
X_train_std = np.concatenate((X_train_scaled, X_train_encode), axis=1)
X_test_std = np.concatenate((X_test_scaled, X_test_encode), axis=1)

"""Sampai di tahap ini, data kita telah siap untuk dilatih menggunakan model machine learning

### Modelling

Pada tahap ini, kita akan mengembangkan model machine learning dengan tiga algoritma. Kemudian, kita akan mengevaluasi performa masing-masing algoritma dan menentukan algoritma mana yang memberikan hasil prediksi terbaik. Ketiga algoritma yang akan kita gunakan, antara lain:

1. Linear Regression
2. Random Forest
3. Extreme Gradient Boosting

#### 1. Linear Regresion Model
"""

# Membangun Linear Regression model
lr_model = LinearRegression(fit_intercept=True, n_jobs=-1)

# Melakukan pelatihan model
lr_model.fit(X_train_std, y_train)

"""#### 2. Random Forest Model"""

# Membangun Random Forest model
rf_model = RandomForestRegressor(max_depth=10, min_samples_leaf=2, n_estimators=400, random_state=123)

# Melakukan pelatihan model
rf_model.fit(X_train_std, y_train)

"""#### 3. XGB Model"""

# Inisialisasi objek XGBRegressor
xgb_model = xgb.XGBRegressor(learning_rate= 0.1, max_depth=3, min_child_weight=4, n_estimators=50, random_state=123)

# Melakukan pelatihan model
xgb_model.fit(X_train_std, y_train)

"""### Evaluation

kita menggunakan metrik RMSE (Root Mean Squard Error) daripada MSE karena memberikan kesalahan dalam unit yang sama dengan variabel target, sehingga lebih mudah diinterpretasikan. RMSE juga memberikan bobot lebih pada kesalahan yang besar, karena mengambil akar kuadrat dari nilai MSE. Selain itu juga dengan R2 yaitu ukuran seberapa baik variabel target dapat dijelaskan oleh fitur-fitur yang digunakan dalam model. Rentang nilai R2 adalah antara 0 hingga 1.
"""

# Metrik Evaluasi untuk data training
lr_train_predictions = lr_model.predict(X_train_std)
rf_train_predictions = rf_model.predict(X_train_std)
xgb_train_predictions = xgb_model.predict(X_train_std)

# Metrik Evaluasi untuk data uji
lr_test_predictions = lr_model.predict(X_test_std)
rf_test_predictions = rf_model.predict(X_test_std)
xgb_test_predictions = xgb_model.predict(X_test_std)

# Menghitung RMSE dan R2 dari model Regresi Linier
lr_train_rmse = np.sqrt(mean_squared_error(y_train, lr_train_predictions))
lr_test_rmse = np.sqrt(mean_squared_error(y_test, lr_test_predictions))
lr_train_r2 = r2_score(y_train, lr_train_predictions)
lr_test_r2 = r2_score(y_test, lr_test_predictions)

# Menghitung RMSE dan R2 dari model Random Forest
rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_train_predictions))
rf_test_rmse = np.sqrt(mean_squared_error(y_test, rf_test_predictions))
rf_train_r2 = r2_score(y_train, rf_train_predictions)
rf_test_r2 = r2_score(y_test, rf_test_predictions)

# Menghitung RMSE dan R2 dari model XGB
xgb_train_rmse = np.sqrt(mean_squared_error(y_train, xgb_train_predictions))
xgb_test_rmse = np.sqrt(mean_squared_error(y_test, xgb_test_predictions))
xgb_train_r2 = r2_score(y_train, xgb_train_predictions)
xgb_test_r2 = r2_score(y_test, xgb_test_predictions)

# Create a DataFrame for the evaluation metrics
eval_metrics = pd.DataFrame({
    'Model': ['Linear Regression', 'Random Forest', 'XGB'],
    'RMSE Train': [lr_train_rmse, rf_train_rmse, xgb_train_rmse],
    'RMSE Test': [lr_test_rmse, rf_test_rmse, xgb_test_rmse],
    'R2 Train': [lr_train_r2, rf_train_r2, xgb_train_r2],
    'R2 Test': [lr_test_r2, rf_test_r2, xgb_test_r2]
})

#Panggil metrik evaluasi
eval_metrics

"""Berdasarkan metrik ini, ketiga algoritma memiliki nilai R2 cukup baik (0.90 lebih untuk data uji), yang menunjukkan bahwa ketiga model ini dapat menjelaskan 90% dari variabilitas dalam data target. Saya cenderung memilih model Random Forest karena memiliki performa yang baik pada data pengujian (RMSE paling rendah dan R2 paling tinggi) serta tingkat overfitting yang lebih rendah dibandingkan dengan XGB.

Setelah itu kita akan mengidentifikasi fitur yang paling penting dengan Random Forest.
"""

# Melakukan pelatihan model
rf_model.fit(X_train_std, y_train)

# Mendapatkan feature importance
importance = rf_model.feature_importances_

# Mendapatkan nama-nama fitur dari data
feature_names = X_train.columns

# Mengurutkan feature importance dari yang tertinggi ke yang terendah
sorted_indices = importance.argsort()[::1]
sorted_importance = importance[sorted_indices]
sorted_feature_names = feature_names[sorted_indices]

# Menampilkan feature importance dalam bentuk grafik batang
plt.figure(figsize=(10, 6))
plt.barh(sorted_feature_names, sorted_importance)
plt.xlabel("Feature Importance")
plt.ylabel("Features")
plt.title("Random Forest Feature Importance")
plt.show()

"""Dari hasil ini diketahui bahwa fitur yang paling penting adalah Ukuran lahan dan diikuti oleh ukuran bangunan"""